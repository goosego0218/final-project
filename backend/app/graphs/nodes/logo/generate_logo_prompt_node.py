# ë¡œê³  í”„ë¡¬í”„íŠ¸ ìƒì„± ë…¸ë“œ
# ì‘ì„±ì¼: 2025-11-27
# ìˆ˜ì •ë‚´ì—­
# - 2025-11-27: ì´ˆê¸° ì‘ì„±
# - 2025-12-04: ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¶”ê°€

from __future__ import annotations
from typing import TYPE_CHECKING, Literal
import json

from langgraph.types import Command
from langchain_core.messages import SystemMessage, HumanMessage

from app.graphs.nodes.logo.prompts import LOGO_GENERATION_SYSTEM_PROMPT, LOGO_STYLE_TRANSFER_SYSTEM_PROMPT,LOGO_EDIT_SYSTEM_PROMPT
from app.graphs.nodes.common.message_utils import get_last_user_message

if TYPE_CHECKING:
    from app.agents.state import AppState, LogoState, BrandProfile
    from langchain_core.language_models.chat_models import BaseChatModel


def make_generate_logo_prompt_node(llm_prompt: "BaseChatModel"):
    """
    ë¸Œëœë“œ ì •ë³´ë¡œ ë¡œê³  í”„ë¡¬í”„íŠ¸ ìƒì„± ë…¸ë“œ íŒ©í† ë¦¬ 
    """
    
    def generate_logo_prompt_node(state: "AppState") -> Command[Literal["generate_logo"]]:
        """
        ë¸Œëœë“œ í”„ë¡œí•„ + ì‚¬ìš©ì ìš”ì²­ â†’ Gemini í”„ë¡¬í”„íŠ¸ ìƒì„±
        (ì°¸ì¡° ì´ë¯¸ì§€ ìœ ë¬´ì— ë”°ë¼ ë¡œì§ ë¶„ê¸°ê¸°)
        """
        # 1) ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
        brand_profile: "BrandProfile" = state.get("brand_profile") or {}
        logo_state: "LogoState" = dict(state.get("logo_state") or {})
        last_user_text = get_last_user_message(state)
        brand_profile_json = json.dumps(brand_profile, ensure_ascii=False, indent=2)

#----------------------------------------25-12-04 ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬--------------------------------
        # ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ í™•ì¸
        reference_images = logo_state.get("reference_images") or []
        has_reference = len(reference_images) > 0
        ref_mode = logo_state.get("ref_mode", "generated_history") # ê¸°ë³¸ê°’

        # [í•µì‹¬ ë¶„ê¸° ë¡œì§]
        if not has_reference:
            # 1. [NEW] ë ˆí¼ëŸ°ìŠ¤ ì—†ìŒ -> ì™„ì „ ìƒì„± ëª¨ë“œ
            print("ğŸ¨ ëª¨ë“œ: New Generation (No Reference)")
            system_prompt_text = LOGO_GENERATION_SYSTEM_PROMPT
            instruction = "Using the system instructions, create a prompt."
            
        elif ref_mode == "user_upload":
            # 2. [STYLE TRANSFER] ìœ ì € ì—…ë¡œë“œ ì´ë¯¸ì§€ -> ìŠ¤íƒ€ì¼ íŠ¸ëœìŠ¤í¼
            print("ğŸ¨ ëª¨ë“œ: Style Transfer (User Upload)")
            system_prompt_text = LOGO_STYLE_TRANSFER_SYSTEM_PROMPT
            instruction = "Using the system instructions and ATTACHED USER IMAGES, create a style transfer prompt."
            
        else:
            # 3. [EDIT] ê¸°ì¡´ ìƒì„± ë¡œê³  -> í¸ì§‘ ëª¨ë“œ
            print("ğŸ¨ ëª¨ë“œ: Edit / Refine (Generated History)")
            system_prompt_text = LOGO_EDIT_SYSTEM_PROMPT
            instruction = "The attached image is the PREVIOUS LOGO we generated. Edit it according to the user request."

        user_prompt = (
            f"You are given the following brand profile and the latest user request.\n\n"
            f"[BRAND PROFILE]\n{brand_profile_json}\n\n"
            f"[LATEST USER REQUEST]\n{last_user_text}\n\n"
            f"{instruction}\n\n"
            "Output ONLY the final prompt text."

        )
#------------------------------------------------------------------------
        messages = [
            SystemMessage(content=system_prompt_text),
            HumanMessage(content=user_prompt),
        ]

        # 3) LLM í˜¸ì¶œ
        ai_msg = llm_prompt.invoke(messages)
        generated_content = getattr(ai_msg, "content", "")
        
        # [2025-12-04 í•µì‹¬ ë¡œì§] LLMì´ ë¦¬ì…‹ í”Œë˜ê·¸ë¥¼ ë³´ëƒˆëŠ”ì§€ í™•ì¸
        # LOGO_REFERENCE_SYSTEM_PROMPTì—ì„œ "[RESET_REFERENCE]"ë¥¼ ë±‰ë„ë¡ ìœ ë„í–ˆìŒ
        if "[RESET_REFERENCE]" in generated_content:
            print("LLM ê°ì§€: ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì‚­ì œ ìš”ì²­")
            # í”Œë˜ê·¸ ì œê±° í›„ í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¹€
            generated_content = generated_content.replace("[RESET_REFERENCE]", "").strip()
            # Stateì—ì„œ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ë¹„ì›€
            logo_state["reference_images"] = []
            # 2. ëª¨ë“œë„ ì´ˆê¸°í™” (í˜¹ì‹œ ëª¨ë¥´ë‹ˆ)
            logo_state["ref_mode"] = "generated_history" 
            
            # [ì¤‘ìš”] ë ˆí¼ëŸ°ìŠ¤ê°€ ì—†ì–´ì¡Œìœ¼ë‹ˆ, ì´ë²ˆ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì€ "New Generation"ìš©ì´ì–´ì•¼ í•¨.
            # í•˜ì§€ë§Œ ì´ë¯¸ ìœ„ì—ì„œ Editìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¼ì„ ìˆ˜ ìˆìŒ.
            # ê°€ì¥ í™•ì‹¤í•œ ê±´, ë¦¬ì…‹ ê°ì§€ ì‹œì—” ê·¸ëƒ¥ "ê¸°ë³¸ ìƒì„± í”„ë¡¬í”„íŠ¸" ë¡œì§ì„ íƒ€ê²Œ í•˜ê±°ë‚˜,
            # LLMì´ ì•Œì•„ì„œ New í”„ë¡¬í”„íŠ¸ë¥¼ ì§°ì„ ê²ƒì´ë¼ ë¯¿ëŠ” ê²ƒ.
            # (Edit í”„ë¡¬í”„íŠ¸ì—ë„ "start fresh" ì§€ì¹¨ì´ ìˆìœ¼ë¯€ë¡œ LLMì´ ì˜ ì§°ì„ ê²ƒì„)
        logo_state["generated_prompt"] = generated_content
        
        return Command(
            update={
                "messages": [ai_msg],
                "logo_state": logo_state, 
            },
            goto="generate_logo",
        )
    
    return generate_logo_prompt_node